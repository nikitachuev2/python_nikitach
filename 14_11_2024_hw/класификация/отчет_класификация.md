
# Отчет о классификации рака молочной железы

## Введение
В данном проекте мы использовали встроенный датасет о раке молочной железы из библиотеки `sklearn` для решения задачи классификации. Задачей было определить, является ли опухоль доброкачественной или злокачественной на основе измерений различных характеристик опухоли.

## Сбор данных
Для работы был использован датасет, содержащий 569 экземпляров с 30 характеристиками опухоли и целевой переменной, указывающей на тип опухоли (0 - доброкачественная, 1 - злокачественная).

## Предобработка данных
1. **Исследование данных**: Проведено изучение структуры данных, недостающих значений и статистических характеристик.
2. **Подготовка данных**: Все признаки были стандартизированы, чтобы привести их к единому масштабу, что особенно важно для некоторых моделей.

## Выбор метрик
Для оценки качества моделей мы использовали следующие метрики:
- **Точность (Accuracy)**: показывает долю правильных предсказаний среди общего числа предсказаний.
- **Отчет по классификации**: включает в себя precision, recall и F1-score для более глубокого анализа эффективности классификации:
  - **Precision**: показывает, насколько из предсказанных положительных классов на самом деле были правильными.
  - **Recall**: показывает, насколько из всех реальных положительных классов были правильно предсказаны.
  - **F1-score**: гармоническое среднее между precision и recall, которое важно, когда необходимо сбалансировать оба показателя.

## Обученные модели
Я обучил и оценил несколько алгоритмов классификации:
1. **Логистическая регрессия**
2. **SVM (машина опорных векторов)**
3. **KNN (к-ближайших соседей)**
4. **Случайный лес (Random Forest)**

### Результаты
На основании оценок моделей, Random Forest показал наилучшие результаты. Его эффективность объясняется тем, что он агрегирует предсказания нескольких деревьев решений и уменьшает вероятность переобучения.

### Итоговые показатели модели Random Forest:
- **Точность**: [указать точность]
- **F1-score**: [указать F1-score]

## Сравнение с CatBoost
Дополнительно мы можем рассмотреть использование алгоритма CatBoost. 

### Что такое CatBoost?
CatBoost - это библиотека для градиентного бустинга, которая способствует обучению моделей на табличных данных и включает в себя несколько особенностей:
- **CAT (Categorical) Features**: автоматическая поддержка категориальных переменных без необходимости их кодирования, что упрощает предобработку данных.
- **Обработка пропусков**: удобные методы для работы с недостающими значениями.
- **Градиентное бустинг**: работает по принципу построения ансамбля слабых моделей, в отличие от других методов, таких как SVM, которые могут использовать линейные разделители.

Сравнив модель Random Forest с CatBoost, пользователи могут получить отличные результаты, особенно в случаях с категориальными признаками и большим количеством данных.

## Заключение
В ходе работы было установлено, что наилучшей моделью на данном датасете оказалась Random Forest. Рекомендуется также сравнить ее с алгоритмами градиентного бустинга, такими как CatBoost, чтобы увидеть, как различные методы могут повлиять на результаты в зависимости от характеристик данных.
